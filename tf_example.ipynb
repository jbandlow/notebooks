{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Launched with docker run -d -p 8888:8888 -v `pwd`:/home/jovyan/work jupyter/tensorflow-notebook start-notebook.sh --NotebookApp.token=''\n",
    "# Based on playing around with https://github.com/aymericdamien/TensorFlow-Examples\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://arxiv.org/pdf/1603.04467.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A TensorFlow computation is described by a directed\n",
    "graph, which is composed of a set of nodes. The graph\n",
    "represents a dataflow computation, with extensions for\n",
    "allowing some kinds of nodes to maintain and update\n",
    "persistent state and for branching and looping control\n",
    "structures within the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a TensorFlow graph, each node has zero or more inputs\n",
    "and zero or more outputs, and represents the instantiation\n",
    "of an operation. Values that flow along normal\n",
    "edges in the graph (from outputs to inputs) are tensors,\n",
    "arbitrary dimensionality arrays where the underlying element\n",
    "type is specified or inferred at graph-construction\n",
    "time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An operation has a name and represents an abstract computation\n",
    "(e.g., “matrix multiply”, or “add”). An operation\n",
    "can have attributes, and all attributes must be provided\n",
    "or inferred at graph-construction time in order to\n",
    "instantiate a node to perform the operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clients programs interact with the TensorFlow system by\n",
    "creating a Session. To create a computation graph, the\n",
    "Session interface supports an Extend method to augment\n",
    "the current graph managed by the session with additional\n",
    "nodes and edges (the initial graph when a session is created\n",
    "is empty). The other primary operation supported\n",
    "by the session interface is Run, which takes a set of output\n",
    "names that need to be computed, as well as an optional\n",
    "set of tensors to be fed into the graph in place of\n",
    "certain outputs of nodes. Using the arguments to Run,\n",
    "the TensorFlow implementation can compute the transitive\n",
    "closure of all nodes that must be executed in order\n",
    "to compute the outputs that were requested, and can then\n",
    "arrange to execute the appropriate nodes in an order that\n",
    "respects their dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most computations a graph is executed multiple times.\n",
    "Most tensors do not survive past a single execution of the\n",
    "graph. However, a Variable is a special kind of operation\n",
    "that returns a handle to a persistent mutable tensor\n",
    "that survives across executions of a graph. Handles to\n",
    "these persistent mutable tensors can be passed to a handful\n",
    "of special operations, such as Assign and AssignAdd\n",
    "(equivalent to +=) that mutate the referenced tensor. For\n",
    "machine learning applications of TensorFlow, the parameters\n",
    "of the model are typically stored in tensors held in\n",
    "variables, and are updated as part of the Run of the training\n",
    "graph for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor in our implementation is a typed, multidimensional\n",
    "array. We support a variety of tensor element\n",
    "types, including signed and unsigned integers ranging\n",
    "in size from 8 bits to 64 bits, IEEE float and double\n",
    "types, a complex number type, and a string type (an arbitrary\n",
    "byte array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, TensorFlow!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Constant op\n",
    "# The op is added as a node to the default graph.\n",
    "#\n",
    "# The value returned by the constructor represents the output\n",
    "# of the Constant op.\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "sess.run(hello) # Returns the value of computing the operation `hello`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 2 b: 3\n",
      "Addition with constants: 5\n",
      "Multiplication with constants: 6\n",
      "Multiple computations in a single run: [2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Basic constant operations\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "with tf.Session() as sess:\n",
    "    print \"a: %i\" % sess.run(a), \"b: %i\" % sess.run(b)\n",
    "    print \"Addition with constants: %i\" % sess.run(a + b)\n",
    "    print \"Multiplication with constants: %i\" % sess.run(a * b)\n",
    "    print \"Multiple computations in a single run: %s\" % sess.run([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition with placeholders: 5\n",
      "Multiplication with placeholders: 20\n"
     ]
    }
   ],
   "source": [
    "# Basic Operations with placeholder as graph input\n",
    "# The value returned by the constructor represents the output\n",
    "# of the Variable op. \n",
    "a = tf.placeholder(tf.int16)\n",
    "b = tf.placeholder(tf.int16)\n",
    "\n",
    "# Define some operations\n",
    "add = tf.add(a, b)\n",
    "mul = tf.multiply(a, b)\n",
    "\n",
    "# Launch the default graph.\n",
    "with tf.Session() as sess:\n",
    "    # Run every operation with variable input\n",
    "    print \"Addition with placeholders: %i\" % sess.run(add, feed_dict={a: 2, b: 3})\n",
    "    print \"Multiplication with placeholders: %i\" % sess.run(mul, feed_dict={a: 4, b: 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial value of x: 0\n",
      "Value of running the operation y: 1\n",
      "Re-computed value of x: 1\n"
     ]
    }
   ],
   "source": [
    "# Define a Variable, which is a tensor that can be updated\n",
    "x = tf.Variable(0)\n",
    "\n",
    "# y is an op that updates x (the result is the updated value)\n",
    "y = tf.assign(x, 1)\n",
    "\n",
    "# One must initialize variables inside a session before using them. There's an op for that.\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print \"Initial value of x: %i\" % sess.run(x)\n",
    "    print \"Value of running the operation y: %i\" % sess.run(y)\n",
    "    print \"Re-computed value of x: %i\" % sess.run(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.]]\n",
      "\n",
      "[[ 6.  6.]\n",
      " [ 6.  6.]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix Multiplication from TensorFlow official tutorial\n",
    "\n",
    "# Create a Constant op that produces a 1x2 matrix.  The op is\n",
    "# added as a node to the default graph.\n",
    "#\n",
    "# The value returned by the constructor represents the output\n",
    "# of the Constant op.\n",
    "matrix1 = tf.constant([[3., 3.]])\n",
    "\n",
    "# Create another Constant that produces a 2x1 matrix.\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "\n",
    "# Create a Matmul op that takes 'matrix1' and 'matrix2' as inputs.\n",
    "# The returned value, 'product', represents the result of the matrix\n",
    "# multiplication.\n",
    "a_product = tf.matmul(matrix1, matrix2)\n",
    "b_product = tf.matmul(matrix2, matrix1)\n",
    "\n",
    "\n",
    "# To run the matmul op we call the session 'run()' method, passing 'product'\n",
    "# which represents the output of the matmul op.  This indicates to the call\n",
    "# that we want to get the output of the matmul op back.\n",
    "#\n",
    "# All inputs needed by the op are run automatically by the session.  They\n",
    "# typically are run in parallel.\n",
    "#\n",
    "# The call 'run(product)' thus causes the execution of threes ops in the\n",
    "# graph: the two constants and matmul.\n",
    "#\n",
    "# The output of the op is returned in 'result' as a numpy `ndarray` object.\n",
    "with tf.Session() as sess:\n",
    "    # Modified to compute both products instead of just one.\n",
    "    result = sess.run([a_product, b_product])\n",
    "print result[0]\n",
    "print\n",
    "print result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 5\n",
    "\n",
    "# tf Graph Input\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape N x 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 10])  # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# Model weights, initialized to 0\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# Construct model\n",
    "# Softmax is applied to each row. Each row becomes a finite prob. dist.\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b) # xW + b adds b to every row of xW (numpy broadcasting)\n",
    "\n",
    "# Minimize error using cross entropy between actual \"distribution\" `y`\n",
    "# and computed distribution `pred`. `reduce_sum(.., axis=1)` sums each row,\n",
    "# and `reduce_mean` averages the rows.\n",
    "\n",
    "#cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(pred), axis=1))\n",
    "\n",
    "# Another example, where cost is |y - pred|^2\n",
    "cost = tf.reduce_mean(tf.reduce_sum(tf.square(y - pred), axis=1))\n",
    "\n",
    "# Another example, now with L1\n",
    "#cost = tf.reduce_mean(tf.reduce_sum(tf.abs(y - pred), axis=1))\n",
    "\n",
    "# Update weights using Gradient Descent\n",
    "# `run`ning the optimizer will compute cost, \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Test model\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0005 cost= 0.146617283\n",
      "Epoch: 0010 cost= 0.130840378\n",
      "Epoch: 0015 cost= 0.123749520\n",
      "Epoch: 0020 cost= 0.119298661\n",
      "Epoch: 0025 cost= 0.116197848\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9267\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle -- we run through the entire training set `training_epochs` times\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        num_batches = int(mnist.train.num_examples/batch_size)\n",
    "        \n",
    "        # Loop over all batches\n",
    "        for unused in range(num_batches):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Fit training using batch data\n",
    "            # Compute the cost and apply the optimizer for a single batch.\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,\n",
    "                                                          y: batch_ys})\n",
    "            \n",
    "            # Running computation of average loss for this epoch\n",
    "            avg_cost += c / num_batches\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if (epoch + 1) % display_step == 0:\n",
    "            print \"Epoch: {:04d} cost= {:.9f}\".format(epoch + 1, avg_cost)\n",
    "\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Calculate accuracy on test set\n",
    "    print \"Accuracy:\", accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
