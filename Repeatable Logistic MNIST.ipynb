{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sheet is playing around with tensorflow, trying to figure out how to manage experimentation from an engineering perspective.  I want to be able to do a lot of runs, tweaking all kinds of things, without having to context-switch to write down the results.  I want the results to be written down for me.\n",
    "\n",
    "This doesn't get all the way there, but it starts to point the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# A local variable for keeping track of various runs\n",
    "# TODO: Figure out how to pickle this.\n",
    "runs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(hyperparams, model_params, model, output, train_data, validation_data, test_data):\n",
    "    \"\"\"Run the model and store some data about it.\n",
    "    \"\"\"\n",
    "    # Parse input.\n",
    "    step_size_map = hyperparams['step_size_map']\n",
    "    num_batches = hyperparams['num_batches']\n",
    "    batch_size = hyperparams['batch_size']\n",
    "    num_outputs = hyperparams['num_outputs']\n",
    "    \n",
    "    x = model_params['x']\n",
    "    y_ = model_params['y_']\n",
    "    W = model_params['W']\n",
    "    b = model_params['b']\n",
    "    y = model_params['y']\n",
    "    \n",
    "    loss = model['loss']\n",
    "    train_step = model['train_step']\n",
    "    \n",
    "    accuracy = output['accuracy']\n",
    "    \n",
    "    # Train the model\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for _ in range(num_batches):\n",
    "            # Adjust the step size\n",
    "            if _ in step_size_map:\n",
    "                step_size = step_size_map[_]\n",
    "                train = train_step(step_size)\n",
    "                print(f'Step size: {step_size}')\n",
    "            \n",
    "            # Load a batch, and train one step it.\n",
    "            xs, ys = train_data.next_batch(batch_size)\n",
    "            sess.run(train, feed_dict={x: xs, y_: ys})\n",
    "            \n",
    "            # Periodic output\n",
    "            if (_ + 1) % (num_batches // num_outputs) == 0:\n",
    "                xs, ys = validation_data.images, validation_data.labels\n",
    "                vld_accuracy = sess.run(accuracy, feed_dict={x: xs, y_: ys})\n",
    "                print(f'Step {_ + 1} accuracy: {vld_accuracy:.3f}')\n",
    "                vld_loss = sess.run(loss, feed_dict={x:xs, y_: ys})\n",
    "                print(f'Step {_ + 1} loss: {vld_loss:.3f}')\n",
    "    \n",
    "        test_accuracy = sess.run(accuracy, feed_dict={x: test_data.images, y_: test_data.labels})\n",
    "        print(f'Test accuracy: {test_accuracy:.3f}')\n",
    "        test_loss = sess.run(loss, feed_dict={x: test_data.images, y_: test_data.labels})\n",
    "        print(f'Test loss: {test_loss:.3f}')\n",
    "        \n",
    "    runs.append({\n",
    "        'time': datetime.datetime.now(),\n",
    "        'hyperparams': hyperparams,\n",
    "        'model_params': model_params,\n",
    "        'model': model,\n",
    "        'output': output,\n",
    "        'accuracy': test_accuracy,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdim = mnist.train.images[0].size\n",
    "xtype = mnist.train.images[0].dtype\n",
    "ydim = mnist.train.labels[0].size\n",
    "\n",
    "x = tf.placeholder(xtype, [None, xdim])\n",
    "y_ = tf.placeholder(xtype, [None, ydim]) \n",
    "W = tf.Variable(tf.zeros([xdim, ydim]))\n",
    "b = tf.Variable(tf.zeros([ydim]))\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "#loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=tf.matmul(x, W) + b))\n",
    "#loss = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "train_step = lambda _: tf.train.GradientDescentOptimizer(_).minimize(loss)\n",
    "\n",
    "model_params = {\n",
    "    'x': x,\n",
    "    'y_': y_,\n",
    "    'W': W,\n",
    "    'b': b,\n",
    "    'y': y,\n",
    "}\n",
    "\n",
    "model = {\n",
    "    'loss': loss, \n",
    "    'train_step': train_step,\n",
    "}\n",
    "\n",
    "output = {\n",
    "    'accuracy': tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1)), tf.float32)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'step_size_map': {0: 3, 2500: 0.3},\n",
    "    'num_batches': 6000,\n",
    "    'batch_size': 100,\n",
    "    'num_outputs': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step size: 3\n",
      "Step 600 accuracy: 0.919\n",
      "Step 600 loss: 1.556\n",
      "Step 1200 accuracy: 0.921\n",
      "Step 1200 loss: 1.547\n",
      "Step 1800 accuracy: 0.926\n",
      "Step 1800 loss: 1.543\n",
      "Step 2400 accuracy: 0.931\n",
      "Step 2400 loss: 1.540\n",
      "Step size: 0.3\n",
      "Step 3000 accuracy: 0.930\n",
      "Step 3000 loss: 1.539\n",
      "Step 3600 accuracy: 0.930\n",
      "Step 3600 loss: 1.539\n",
      "Step 4200 accuracy: 0.931\n",
      "Step 4200 loss: 1.538\n",
      "Step 4800 accuracy: 0.931\n",
      "Step 4800 loss: 1.539\n",
      "Step 5400 accuracy: 0.930\n",
      "Step 5400 loss: 1.538\n",
      "Step 6000 accuracy: 0.930\n",
      "Step 6000 loss: 1.538\n",
      "Test accuracy: 0.927\n",
      "Test loss: 1.541\n"
     ]
    }
   ],
   "source": [
    "run(hyperparams, model_params, model, output, mnist.train, mnist.validation, mnist.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the inner loop in `run()` is:\n",
    "```\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for _ in range(num_batches):\n",
    "        # Adjust the step size\n",
    "        if _ in step_size_map:\n",
    "            step_size = step_size_map[_]\n",
    "            train = train_step(step_size)\n",
    "            print('Step size: {}'.format(step_size))\n",
    "\n",
    "        # Load a batch, and train one step it.\n",
    "        xs, ys = train_data.next_batch(batch_size)\n",
    "        sess.run(train, feed_dict={x: xs, y_: ys})\n",
    "\n",
    "        # Periodic output\n",
    "        if (_ + 1) % (num_batches // num_outputs) == 0:\n",
    "            vld_accuracy = sess.run(\n",
    "                accuracy, \n",
    "                feed_dict={x: validation_data.images, y_: validation_data.labels})\n",
    "            print('Step {} accuracy: {:.3f}'.format(_ + 1, vld_accuracy))\n",
    "```\n",
    "\n",
    "The inner-loop in the CNN MNIST [example](https://www.tensorflow.org/get_started/mnist/pros) looks like this:\n",
    "```\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(num_batches):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        # Periodic output\n",
    "        if i % 100 == 0:\n",
    "              train_accuracy = accuracy.eval(feed_dict={\n",
    "                  x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "    \n",
    "        # Train the batch:\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "```\n",
    "which is more-or-less identical.  This gives me hope that I can make this fairly generic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_session(get_train_data, num_batches, train_step=None, train_step_update=None, \n",
    "                output_cnd=None, output_fn=None, final_output_fn=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "     - get_train_data: A function which returns (features, labels) for a single batch.\n",
    "     - num_batches: The number of batches to process\n",
    "     - train_step: An optimizer of the form of those in `tf.train`\n",
    "     - train_step_update: a function of `sess` and the current iteration number that returns an\n",
    "         updated `train_step`. If this function returns `None`, `train_step` will not be updated.     \n",
    "     - output_cnd: A function of the current iteration number, that returns True if we should print intermediate\n",
    "         output at this iteration.\n",
    "     - output_fn: A function of `sess` and the current iteration number that prints intermediate output.\n",
    "     - final_output_fn: A function of `sess` that produces any final output immediately before closing the session.\n",
    "    \"\"\"\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for _ in range(num_batches):\n",
    "            # Update training step, if necessary:\n",
    "            if train_step_update is not None:\n",
    "                update = train_step_update(sess, _)\n",
    "                if update is not None:\n",
    "                    train_step = update\n",
    "\n",
    "            # Load and train\n",
    "            xs, ys = get_train_data()\n",
    "            sess.run(train_step, feed_dict={x: xs, y_: ys})\n",
    "            \n",
    "            # Conditional Output\n",
    "            if output_cnd is not None and output_cnd(_):\n",
    "                output_fn(sess, _)\n",
    "                \n",
    "        if final_output_fn is not None:        \n",
    "            final_output_fn(sess)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_train_data = lambda: mnist.train.next_batch(hyperparams['batch_size'])\n",
    "def train_step_update(sess, i): \n",
    "    return train_step(hyperparams['step_size_map'][i]) if i in hyperparams['step_size_map'] else None\n",
    "def output_cnd(i):\n",
    "    return (i + 1) % (hyperparams['num_batches'] // hyperparams['num_outputs']) == 0\n",
    "def output_fn(sess, _):\n",
    "    validation_data = mnist.validation\n",
    "    xs, ys = validation_data.images, validation_data.labels\n",
    "    vld_accuracy = sess.run(output['accuracy'], feed_dict={x: xs, y_: ys})\n",
    "    print(f'Step {_ + 1} accuracy: {vld_accuracy:.3f}')\n",
    "    vld_loss = sess.run(model['loss'], feed_dict={x:xs, y_: ys})\n",
    "    print(f'Step {_ + 1} loss: {vld_loss:.3f}')\n",
    "def final_output_fn(sess):\n",
    "    print()\n",
    "    test_data = mnist.test\n",
    "    test_accuracy = sess.run(output['accuracy'], feed_dict={x: test_data.images, y_: test_data.labels})\n",
    "    print(f'Test accuracy: {test_accuracy:.3f}')\n",
    "    test_loss = sess.run(model['loss'], feed_dict={x: test_data.images, y_: test_data.labels})\n",
    "    print(f'Test loss: {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 accuracy: 0.915\n",
      "Step 600 loss: 1.558\n",
      "Step 1200 accuracy: 0.924\n",
      "Step 1200 loss: 1.547\n",
      "Step 1800 accuracy: 0.927\n",
      "Step 1800 loss: 1.542\n",
      "Step 2400 accuracy: 0.926\n",
      "Step 2400 loss: 1.542\n",
      "Step 3000 accuracy: 0.931\n",
      "Step 3000 loss: 1.538\n",
      "Step 3600 accuracy: 0.931\n",
      "Step 3600 loss: 1.538\n",
      "Step 4200 accuracy: 0.930\n",
      "Step 4200 loss: 1.538\n",
      "Step 4800 accuracy: 0.932\n",
      "Step 4800 loss: 1.538\n",
      "Step 5400 accuracy: 0.931\n",
      "Step 5400 loss: 1.538\n",
      "Step 6000 accuracy: 0.930\n",
      "Step 6000 loss: 1.538\n",
      "\n",
      "Test accuracy: 0.926\n",
      "Test loss: 1.541\n"
     ]
    }
   ],
   "source": [
    "run_session(\n",
    "    get_train_data=get_train_data, \n",
    "    num_batches=hyperparams['num_batches'], \n",
    "    train_step_update=train_step_update, \n",
    "    output_cnd=output_cnd, \n",
    "    output_fn=output_fn, \n",
    "    final_output_fn=final_output_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams['num_batches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.nn.conv2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
